# Workshop : Dockerisation d'une Application Jupyter + PySpark + MongoDB

## ğŸ¯ Objectif du Workshop

Apprendre Ã  dockeriser une application de data science avec :
- **Jupyter Notebook** avec **PySpark** pour l'analyse de donnÃ©es
- **MongoDB** pour le stockage des donnÃ©es
- **Docker Compose** pour orchestrer les services

---

## ğŸ“‹ PrÃ©requis

- Docker et Docker Compose installÃ©s
- Connaissances de base en Python et Jupyter
- Ã‰diteur de code (VS Code recommandÃ©)

---

## ğŸ“ Structure du Projet Ã  CrÃ©er

```
jupyter-project/
â”‚
â”œâ”€â”€ docker-compose.yml          # Ã€ crÃ©er : orchestration des services
â”œâ”€â”€ Dockerfile                  # Ã€ crÃ©er : image Jupyter personnalisÃ©e
â”œâ”€â”€ requirements.txt            # Ã€ crÃ©er : dÃ©pendances Python
â”œâ”€â”€ data/                       # Dossier pour les donnÃ©es
â”‚   â””â”€â”€ input.csv               # Fichier de donnÃ©es
â”œâ”€â”€ notebooks/                  # Dossier pour les notebooks
â”‚   â””â”€â”€ analysis.ipynb
â””â”€â”€ load.ipynb                  # Notebook principal
```

---

## ğŸš€ Ã‰tape 1 : CrÃ©er le fichier requirements.txt

### Objectif
DÃ©finir toutes les dÃ©pendances Python nÃ©cessaires pour le projet.

### Instructions

1. CrÃ©ez le fichier `requirements.txt` Ã  la racine du projet

2. Contenu du fichier :

```txt
# Data Processing
pandas>=2.0.0
numpy>=1.24.0

# Database Connectors
pymongo>=4.0.0
psycopg2-binary>=2.9.0

# Data Visualization
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.17.0

# Spark Extensions
pyspark>=3.5.0

# Utilities
python-dotenv>=1.0.0
```

### ğŸ“ Points ClÃ©s Ã  Expliquer

- **pandas** : Manipulation et analyse de donnÃ©es
- **pymongo** : Connexion Ã  MongoDB
- **matplotlib/seaborn/plotly** : Visualisation de donnÃ©es
- **pyspark** : Analyse distribuÃ©e avec Spark
- **python-dotenv** : Gestion des variables d'environnement

---

## ğŸš€ Ã‰tape 2 : CrÃ©er le Dockerfile

### Objectif
CrÃ©er une image Docker personnalisÃ©e basÃ©e sur Jupyter avec PySpark intÃ©grÃ©.

### Instructions

1. CrÃ©ez le fichier `Dockerfile` Ã  la racine du projet

2. Contenu du Dockerfile :

```dockerfile
# Image de base : Jupyter avec PySpark 3.5.0 prÃ©installÃ©
FROM jupyter/pyspark-notebook:spark-3.5.0

# Passer en mode root pour installer des paquets systÃ¨me
USER root

# Installer les outils MongoDB et autres dÃ©pendances systÃ¨me
RUN apt-get update && apt-get install -y \
    wget \              # Outil de tÃ©lÃ©chargement de fichiers
    curl \              # Outil de transfert de donnÃ©es
    && rm -rf /var/lib/apt/lists/*  # Nettoyer le cache pour rÃ©duire la taille

# Revenir Ã  l'utilisateur jovyan (utilisateur par dÃ©faut de Jupyter)
USER $NB_UID

# DÃ©finir le rÃ©pertoire de travail
WORKDIR /home/jovyan/work

# Copier le fichier des dÃ©pendances Python
COPY requirements.txt .

# Installer les dÃ©pendances Python sans cache
RUN pip install --no-cache-dir -r requirements.txt

# Copier tous les fichiers du projet avec les bonnes permissions
COPY --chown=$NB_UID:$NB_GID . .

# Exposer le port Jupyter Notebook (8888)
EXPOSE 8888

# Exposer le port Spark UI (4040)
EXPOSE 4040

# Commande de dÃ©marrage : lancer Jupyter sans authentification
CMD ["start-notebook.sh", "--NotebookApp.token=''", "--NotebookApp.password=''"]
```

### ğŸ“ Explication Ligne par Ligne

#### Section 1 : Image de Base
```dockerfile
FROM jupyter/pyspark-notebook:spark-3.5.0
```
- Utilise l'image officielle Jupyter qui inclut :
  - Python 3.x
  - Jupyter Notebook/Lab
  - PySpark 3.5.0 prÃ©configurÃ©
  - Toutes les dÃ©pendances Spark

#### Section 2 : Installation des Outils SystÃ¨me
```dockerfile
USER root
RUN apt-get update && apt-get install -y \
    wget \
    curl \
    && rm -rf /var/lib/apt/lists/*
```
- **USER root** : Passe en mode administrateur (nÃ©cessaire pour apt-get)
- **apt-get update** : Met Ã  jour la liste des paquets
- **apt-get install** : Installe wget et curl
- **rm -rf /var/lib/apt/lists/** : Nettoie le cache pour rÃ©duire la taille de l'image

#### Section 3 : Configuration Utilisateur
```dockerfile
USER $NB_UID
WORKDIR /home/jovyan/work
```
- **USER $NB_UID** : Revient Ã  l'utilisateur non-privilÃ©giÃ© (jovyan) pour la sÃ©curitÃ©
- **WORKDIR** : DÃ©finit le rÃ©pertoire de travail (oÃ¹ s'ouvriront les notebooks)

#### Section 4 : Installation des DÃ©pendances Python
```dockerfile
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
```
- **COPY requirements.txt** : Copie uniquement requirements.txt en premier (optimisation du cache Docker)
- **pip install --no-cache-dir** : Installe les packages sans garder le cache (rÃ©duit la taille)

#### Section 5 : Copie des Fichiers du Projet
```dockerfile
COPY --chown=$NB_UID:$NB_GID . .
```
- **COPY --chown** : Copie tous les fichiers avec les bonnes permissions
- **$NB_UID:$NB_GID** : Assigne les fichiers Ã  l'utilisateur jovyan

#### Section 6 : Exposition des Ports
```dockerfile
EXPOSE 8888
EXPOSE 4040
```
- **8888** : Port pour accÃ©der Ã  Jupyter Notebook
- **4040** : Port pour l'interface de monitoring Spark

#### Section 7 : Commande de DÃ©marrage
```dockerfile
CMD ["start-notebook.sh", "--NotebookApp.token=''", "--NotebookApp.password=''"]
```
- **start-notebook.sh** : Script fourni par l'image Jupyter
- **--NotebookApp.token=''** : DÃ©sactive le token d'authentification
- **--NotebookApp.password=''** : DÃ©sactive le mot de passe
- âš ï¸ **ATTENTION** : Ne jamais utiliser en production ! (pour le dÃ©veloppement uniquement)

---

## ğŸš€ Ã‰tape 3 : CrÃ©er le fichier docker-compose.yml

### Objectif
Orchestrer les services Jupyter et MongoDB et dÃ©finir leur communication.

### Instructions

1. CrÃ©ez le fichier `docker-compose.yml` Ã  la racine du projet

2. Contenu du docker-compose.yml :

```yaml
version: '3.8'

services:
  # Service MongoDB
  mongodb:
    image: mongo:7.0                          # Image MongoDB version 7.0
    container_name: dataflow-insight-mongo    # Nom personnalisÃ© du conteneur
    ports:
      - "27017:27017"                         # Port MongoDB (host:container)
    environment:
      MONGO_INITDB_DATABASE: dataflow_insight # Nom de la base de donnÃ©es initiale
    volumes:
      - mongodb_data:/data/db                 # Volume pour persister les donnÃ©es
    networks:
      - dataflow-insight-net                  # RÃ©seau partagÃ© avec Jupyter

  # Service Jupyter avec PySpark
  jupyter:
    build: .                                  # Construire depuis le Dockerfile local
    container_name: dataflow-insight-jupyter  # Nom personnalisÃ© du conteneur
    ports:
      - "8888:8888"                           # Port Jupyter Notebook
      - "4041:4040"                           # Port Spark UI (redirigÃ© vers 4041)
    environment:
      - JUPYTER_ENABLE_LAB=yes                # Active JupyterLab (interface moderne)
      - GRANT_SUDO=yes                        # Permet les commandes sudo
    volumes:
      - ./data:/home/jovyan/work/data                     # Partage le dossier data
      - ./load.ipynb:/home/jovyan/work/load.ipynb         # Monte le notebook principal
      - ./notebooks:/home/jovyan/work/notebooks           # Partage le dossier notebooks
    depends_on:
      - mongodb                               # DÃ©marre MongoDB avant Jupyter
    networks:
      - dataflow-insight-net                  # RÃ©seau partagÃ© avec MongoDB

# DÃ©claration des volumes persistants
volumes:
  mongodb_data:                               # Volume pour les donnÃ©es MongoDB

# DÃ©claration des rÃ©seaux
networks:
  dataflow-insight-net:                       # RÃ©seau bridge pour communication
    driver: bridge
```

### ğŸ“ Explication DÃ©taillÃ©e du Docker Compose

#### Service MongoDB

##### Configuration de Base
```yaml
mongodb:
  image: mongo:7.0
  container_name: dataflow-insight-mongo
```
- **image: mongo:7.0** : Utilise l'image officielle MongoDB version 7.0
- **container_name** : Nom fixe pour faciliter les rÃ©fÃ©rences

##### Ports
```yaml
ports:
  - "27017:27017"
```
- **Format** : `host:container`
- **27017** : Port par dÃ©faut de MongoDB
- Permet d'accÃ©der Ã  MongoDB depuis l'hÃ´te (localhost:27017)

##### Variables d'Environnement
```yaml
environment:
  MONGO_INITDB_DATABASE: dataflow_insight
```
- CrÃ©e automatiquement une base de donnÃ©es nommÃ©e `dataflow_insight` au premier dÃ©marrage

##### Volumes
```yaml
volumes:
  - mongodb_data:/data/db
```
- **mongodb_data** : Volume Docker nommÃ© (dÃ©fini en bas du fichier)
- **/data/db** : Chemin interne oÃ¹ MongoDB stocke ses donnÃ©es
- **Persistance** : Les donnÃ©es survivent Ã  l'arrÃªt/suppression du conteneur

##### RÃ©seaux
```yaml
networks:
  - dataflow-insight-net
```
- Connecte MongoDB au rÃ©seau personnalisÃ©
- Permet Ã  Jupyter de communiquer avec MongoDB via le nom `mongodb`

---

#### Service Jupyter

##### Configuration de Base
```yaml
jupyter:
  build: .
  container_name: dataflow-insight-jupyter
```
- **build: .** : Construit l'image depuis le Dockerfile dans le rÃ©pertoire courant
- PrÃ©fÃ©rÃ© Ã  `image:` car on utilise une image personnalisÃ©e

##### Ports
```yaml
ports:
  - "8888:8888"  # Jupyter
  - "4041:4040"  # Spark UI
```
- **8888:8888** : AccÃ¨s Ã  Jupyter via http://localhost:8888
- **4041:4040** : Spark UI accessible via http://localhost:4041
  - Port hÃ´te diffÃ©rent (4041) pour Ã©viter les conflits

##### Variables d'Environnement
```yaml
environment:
  - JUPYTER_ENABLE_LAB=yes
  - GRANT_SUDO=yes
```
- **JUPYTER_ENABLE_LAB=yes** : Active JupyterLab (interface moderne et puissante)
- **GRANT_SUDO=yes** : Permet d'exÃ©cuter des commandes root si nÃ©cessaire

##### Volumes (Montage Bidirectionnel)
```yaml
volumes:
  - ./data:/home/jovyan/work/data
  - ./load.ipynb:/home/jovyan/work/load.ipynb
  - ./notebooks:/home/jovyan/work/notebooks
```

**Format** : `chemin_hÃ´te:chemin_conteneur`

1. **./data:/home/jovyan/work/data**
   - Partage le dossier `data` de l'hÃ´te avec le conteneur
   - Les modifications sont synchronisÃ©es dans les deux sens
   - Permet de lire/Ã©crire des fichiers CSV, JSON, etc.

2. **./load.ipynb:/home/jovyan/work/load.ipynb**
   - Monte un notebook spÃ©cifique
   - Permet d'Ã©diter le notebook depuis l'hÃ´te ou le conteneur

3. **./notebooks:/home/jovyan/work/notebooks**
   - Partage un dossier entier de notebooks
   - Facilite l'organisation de plusieurs notebooks

**Avantages des volumes** :
- âœ… Modifications persistantes
- âœ… Ã‰dition depuis VS Code ou Jupyter
- âœ… Backup facile (les fichiers sont sur l'hÃ´te)
- âœ… Travail collaboratif (partage de fichiers)

##### DÃ©pendances
```yaml
depends_on:
  - mongodb
```
- DÃ©marre MongoDB avant Jupyter
- Assure que MongoDB est disponible quand Jupyter dÃ©marre
- âš ï¸ Ne garantit pas que MongoDB soit prÃªt (juste dÃ©marrÃ©)

##### RÃ©seaux
```yaml
networks:
  - dataflow-insight-net
```
- MÃªme rÃ©seau que MongoDB
- Permet la communication : Jupyter peut accÃ©der Ã  MongoDB via `mongodb:27017`

---

#### Volumes NommÃ©s

```yaml
volumes:
  mongodb_data:
```
- **mongodb_data** : Volume gÃ©rÃ© par Docker
- StockÃ© dans `/var/lib/docker/volumes/` (Linux/Mac) ou dans WSL (Windows)
- Persiste mÃªme aprÃ¨s `docker-compose down`
- SupprimÃ© seulement avec `docker-compose down -v`

---

#### RÃ©seaux

```yaml
networks:
  dataflow-insight-net:
    driver: bridge
```
- **driver: bridge** : RÃ©seau de type pont (par dÃ©faut)
- CrÃ©e un rÃ©seau privÃ© virtuel pour les conteneurs
- Les conteneurs peuvent communiquer par leur nom :
  - Depuis Jupyter : `mongodb://mongodb:27017/dataflow_insight`
  - Le nom `mongodb` est rÃ©solu automatiquement

**Avantages du rÃ©seau personnalisÃ©** :
- âœ… Isolation : seuls les conteneurs du rÃ©seau peuvent communiquer
- âœ… RÃ©solution DNS automatique par nom de conteneur
- âœ… SÃ©curitÃ© accrue

---

## ğŸš€ Ã‰tape 4 : PrÃ©parer les DonnÃ©es

### Instructions

1. CrÃ©ez le dossier `data/` :
```bash
mkdir data
```

2. CrÃ©ez le fichier `data/input.csv` avec des donnÃ©es de test :

```csv
id,name,category,value,date
1,Product A,Electronics,299.99,2024-01-15
2,Product B,Clothing,49.99,2024-01-16
3,Product C,Food,12.50,2024-01-17
4,Product D,Electronics,599.99,2024-01-18
5,Product E,Clothing,79.99,2024-01-19
6,Product F,Food,8.99,2024-01-20
7,Product G,Electronics,199.99,2024-01-21
8,Product H,Clothing,39.99,2024-01-22
9,Product I,Food,15.00,2024-01-23
10,Product J,Electronics,399.99,2024-01-24
```

---

## ğŸš€ Ã‰tape 5 : CrÃ©er un Notebook de DÃ©monstration

### Instructions

1. CrÃ©ez le fichier `load.ipynb` Ã  la racine du projet

2. Contenu du notebook (exemple de code) :

```python
# Cell 1: Import des bibliothÃ¨ques
import pandas as pd
import pymongo
from pyspark.sql import SparkSession

# Cell 2: Initialiser Spark
spark = SparkSession.builder \
    .appName("DataFlow Insight") \
    .getOrCreate()

print("Spark Version:", spark.version)

# Cell 3: Charger les donnÃ©es CSV
df = pd.read_csv('/home/jovyan/work/data/input.csv')
print("DonnÃ©es chargÃ©es:")
print(df.head())

# Cell 4: Connexion Ã  MongoDB
client = pymongo.MongoClient("mongodb://mongodb:27017/")
db = client["dataflow_insight"]
collection = db["products"]

print("ConnectÃ© Ã  MongoDB")

# Cell 5: InsÃ©rer les donnÃ©es dans MongoDB
data_dict = df.to_dict("records")
collection.insert_many(data_dict)
print(f"{len(data_dict)} documents insÃ©rÃ©s dans MongoDB")

# Cell 6: VÃ©rifier l'insertion
count = collection.count_documents({})
print(f"Nombre total de documents: {count}")

# Cell 7: Analyse avec PySpark
spark_df = spark.createDataFrame(df)
spark_df.show()

# Cell 8: Statistiques de base
print("\nStatistiques par catÃ©gorie:")
spark_df.groupBy("category").count().show()
```

---

## ğŸš€ Ã‰tape 6 : Lancer l'Application

### Instructions

1. **Construire et dÃ©marrer les services** :

```bash
docker-compose up -d --build
```

2. **VÃ©rifier l'Ã©tat des conteneurs** :

```bash
docker-compose ps
```

RÃ©sultat attendu :
```
NAME                         STATUS    PORTS
dataflow-insight-jupyter     Up        0.0.0.0:8888->8888/tcp, 0.0.0.0:4041->4040/tcp
dataflow-insight-mongo       Up        0.0.0.0:27017->27017/tcp
```

3. **VÃ©rifier les logs** :

```bash
# Logs de tous les services
docker-compose logs

# Logs d'un service spÃ©cifique
docker-compose logs jupyter
docker-compose logs mongodb

# Suivre les logs en temps rÃ©el
docker-compose logs -f jupyter
```

---

## ğŸš€ Ã‰tape 7 : Utiliser l'Application

### 1. AccÃ©der Ã  Jupyter

**URL** : http://localhost:8888

- Pas de mot de passe requis (configurÃ© dans le Dockerfile)
- Vous verrez l'interface JupyterLab
- Les dossiers `data/`, `notebooks/` et le fichier `load.ipynb` sont visibles

### 2. Ouvrir et ExÃ©cuter le Notebook

1. Cliquez sur `load.ipynb`
2. ExÃ©cutez les cellules une par une (Shift + Enter)
3. VÃ©rifiez les sorties de chaque cellule

### 3. VÃ©rifier Spark UI

**URL** : http://localhost:4041 (quand Spark est actif)

- Monitoring des jobs Spark
- Statistiques de performance
- DÃ©tails des tÃ¢ches exÃ©cutÃ©es

### 4. VÃ©rifier MongoDB

**Via CLI Docker** :
```bash
docker exec -it dataflow-insight-mongo mongosh
```

**Commandes MongoDB** :
```javascript
// Afficher les bases de donnÃ©es
show dbs

// Utiliser la base dataflow_insight
use dataflow_insight

// Afficher les collections
show collections

// Afficher tous les documents
db.products.find().pretty()

// Compter les documents
db.products.countDocuments()

// Recherche par catÃ©gorie
db.products.find({category: "Electronics"}).pretty()

// Statistiques
db.products.aggregate([
  {$group: {_id: "$category", count: {$sum: 1}}}
])
```

### 5. Connexion MongoDB depuis Python

Dans vos notebooks, utilisez cette URL de connexion :

```python
# Format : mongodb://nom_conteneur:port/nom_database
mongo_url = "mongodb://mongodb:27017/dataflow_insight"

# Avec pymongo
import pymongo
client = pymongo.MongoClient(mongo_url)
db = client["dataflow_insight"]
```

**Pourquoi `mongodb` et pas `localhost` ?**
- `mongodb` : Nom du conteneur dans le rÃ©seau Docker
- Docker rÃ©sout automatiquement ce nom vers l'IP du conteneur
- `localhost` ne fonctionnerait pas (rÃ©fÃ©rencerait le conteneur Jupyter lui-mÃªme)

---

## ğŸ”§ Commandes Docker Utiles

### Gestion des Services

```bash
# DÃ©marrer les services
docker-compose up -d

# ArrÃªter les services
docker-compose down

# ArrÃªter et supprimer les volumes (âš ï¸ supprime les donnÃ©es MongoDB)
docker-compose down -v

# Reconstruire les images
docker-compose build

# Reconstruire et redÃ©marrer
docker-compose up -d --build

# RedÃ©marrer un service spÃ©cifique
docker-compose restart jupyter
docker-compose restart mongodb
```

### Logs et Debugging

```bash
# Voir tous les logs
docker-compose logs

# Logs d'un service
docker-compose logs jupyter
docker-compose logs mongodb

# Suivre les logs en temps rÃ©el
docker-compose logs -f

# Logs des 50 derniÃ¨res lignes
docker-compose logs --tail=50
```

### AccÃ¨s aux Conteneurs

```bash
# Shell dans le conteneur Jupyter
docker exec -it dataflow-insight-jupyter bash

# Shell dans MongoDB
docker exec -it dataflow-insight-mongo mongosh

# Shell en tant que root
docker exec -it -u root dataflow-insight-jupyter bash
```

### Inspection et Monitoring

```bash
# Informations dÃ©taillÃ©es sur un conteneur
docker inspect dataflow-insight-jupyter

# Statistiques en temps rÃ©el
docker stats

# Voir les volumes
docker volume ls

# Voir les rÃ©seaux
docker network ls

# Inspecter un rÃ©seau
docker network inspect docker-workshop_dataflow-insight-net
```

---

## ğŸ› RÃ©solution des ProblÃ¨mes Courants

### ProblÃ¨me 1 : Port 8888 dÃ©jÃ  utilisÃ©

**SymptÃ´me** :
```
Bind for 0.0.0.0:8888 failed: port is already allocated
```

**Solutions** :

1. **Changer le port dans docker-compose.yml** :
```yaml
ports:
  - "8889:8888"  # Utiliser le port 8889 sur l'hÃ´te
```

2. **Trouver et arrÃªter le processus** :
```bash
# Windows
netstat -ano | findstr :8888
taskkill /PID <PID> /F

# Linux/Mac
lsof -i :8888
kill -9 <PID>
```

---

### ProblÃ¨me 2 : Jupyter ne trouve pas le fichier CSV

**SymptÃ´me** :
```
FileNotFoundError: [Errno 2] No such file or directory: '/home/jovyan/work/data/input.csv'
```

**Solutions** :

1. **VÃ©rifier le volume dans docker-compose.yml** :
```yaml
volumes:
  - ./data:/home/jovyan/work/data
```

2. **VÃ©rifier que le fichier existe sur l'hÃ´te** :
```bash
ls -la data/input.csv
```

3. **VÃ©rifier dans le conteneur** :
```bash
docker exec -it dataflow-insight-jupyter ls -la /home/jovyan/work/data
```

4. **VÃ©rifier les permissions** :
```bash
chmod 644 data/input.csv
```

---

### ProblÃ¨me 3 : Impossible de se connecter Ã  MongoDB

**SymptÃ´me** :
```
pymongo.errors.ServerSelectionTimeoutError: mongodb:27017: [Errno -2] Name or service not known
```

**Solutions** :

1. **VÃ©rifier que MongoDB est dÃ©marrÃ©** :
```bash
docker-compose ps mongodb
```

2. **VÃ©rifier les logs MongoDB** :
```bash
docker-compose logs mongodb
```

3. **Tester la connexion rÃ©seau** :
```bash
docker exec -it dataflow-insight-jupyter ping mongodb
```

4. **VÃ©rifier le rÃ©seau** :
```bash
docker network ls
docker network inspect docker-workshop_dataflow-insight-net
```

5. **Utiliser la bonne URL de connexion** :
```python
# âœ… Correct (dans Docker)
client = pymongo.MongoClient("mongodb://mongodb:27017/")

# âŒ Incorrect
client = pymongo.MongoClient("mongodb://localhost:27017/")
```

---

### ProblÃ¨me 4 : Erreur "Permission Denied"

**SymptÃ´me** :
```
PermissionError: [Errno 13] Permission denied: '/home/jovyan/work/data/output.csv'
```

**Solutions** :

1. **Changer les permissions du dossier** :
```bash
chmod -R 777 data/
```

2. **VÃ©rifier l'utilisateur dans le conteneur** :
```bash
docker exec -it dataflow-insight-jupyter whoami
# Devrait afficher : jovyan
```

3. **Relancer avec les bonnes permissions** :
```bash
docker-compose down
chmod -R 777 data/
docker-compose up -d
```

---

### ProblÃ¨me 5 : Spark UI n'est pas accessible

**SymptÃ´me** : http://localhost:4041 ne rÃ©pond pas

**Solutions** :

1. **VÃ©rifier que Spark est actif** :
   - Spark UI n'est disponible que quand un job Spark est en cours
   - ExÃ©cutez une cellule avec du code PySpark

2. **VÃ©rifier le port dans docker-compose.yml** :
```yaml
ports:
  - "4041:4040"  # Port hÃ´te : Port conteneur
```

3. **Voir les logs** :
```bash
docker-compose logs jupyter | grep spark
```

---

### ProblÃ¨me 6 : Le conteneur redÃ©marre en boucle

**SymptÃ´me** :
```bash
docker-compose ps
# STATUS: Restarting
```

**Solutions** :

1. **Voir les logs d'erreur** :
```bash
docker-compose logs jupyter
```

2. **VÃ©rifier la syntaxe du Dockerfile** :
```bash
docker-compose build jupyter
```

3. **Tester l'image manuellement** :
```bash
docker run -it --rm jupyter/pyspark-notebook:spark-3.5.0 bash
```

4. **Reconstruire from scratch** :
```bash
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

---

## ğŸ“Š Architecture du Projet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Docker Host                          â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚          Network: dataflow-insight-net           â”‚  â”‚
â”‚  â”‚                                                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚                  â”‚    â”‚                  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  Jupyter + Spark â”‚â—„â”€â”€â”€â”¤    MongoDB      â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                  â”‚    â”‚                  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  Port: 8888      â”‚    â”‚  Port: 27017    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  Spark UI: 4040  â”‚    â”‚                  â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚           â”‚                       â”‚            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚              â”‚                       â”‚                â”‚
â”‚              â–¼                       â–¼                â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚      â”‚   Volumes    â”‚        â”‚   Volumes   â”‚        â”‚
â”‚      â”‚  ./data      â”‚        â”‚ mongodb_dataâ”‚        â”‚
â”‚      â”‚  ./notebooks â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚      â”‚  ./load.ipynbâ”‚                                â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–²              â–²               â–²
        â”‚              â”‚               â”‚
    Port 8888      Port 4041      Port 27017
        â”‚              â”‚               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                Browser Access
```

---

## âœ… CritÃ¨res de RÃ©ussite du Workshop

Ã€ la fin du workshop, vous devez avoir :

1. âœ… CrÃ©Ã© le `Dockerfile` pour Jupyter avec PySpark
2. âœ… CrÃ©Ã© le fichier `requirements.txt` avec toutes les dÃ©pendances
3. âœ… CrÃ©Ã© le `docker-compose.yml` orchestrant Jupyter et MongoDB
4. âœ… LancÃ© les deux conteneurs avec succÃ¨s
5. âœ… AccÃ©dÃ© Ã  JupyterLab via http://localhost:8888
6. âœ… ChargÃ© des donnÃ©es CSV dans un DataFrame pandas
7. âœ… InsÃ©rÃ© des donnÃ©es dans MongoDB
8. âœ… VÃ©rifiÃ© les donnÃ©es dans MongoDB via mongosh
9. âœ… UtilisÃ© PySpark pour analyser les donnÃ©es
10. âœ… Compris la communication entre conteneurs via le rÃ©seau Docker

---

## ğŸ“ Concepts Docker Appris

### Dockerfile
- âœ… Utilisation d'images de base spÃ©cialisÃ©es
- âœ… Gestion des utilisateurs (root vs user)
- âœ… Installation de dÃ©pendances systÃ¨me et Python
- âœ… Copie de fichiers avec permissions appropriÃ©es
- âœ… Exposition de ports multiples
- âœ… Configuration de la commande de dÃ©marrage

### Docker Compose
- âœ… DÃ©finition de services multiples
- âœ… Build vs image (quand construire vs utiliser une image)
- âœ… Montage de volumes (bind mounts)
- âœ… Volumes nommÃ©s pour la persistance
- âœ… Configuration des rÃ©seaux personnalisÃ©s
- âœ… Gestion des dÃ©pendances entre services
- âœ… Variables d'environnement

### RÃ©seaux Docker
- âœ… Communication inter-conteneurs par nom
- âœ… RÃ©solution DNS automatique
- âœ… Isolation rÃ©seau

### Volumes
- âœ… Partage bidirectionnel hÃ´te-conteneur
- âœ… Persistance des donnÃ©es
- âœ… Volumes nommÃ©s vs bind mounts

---

## ğŸ† DÃ©fis Bonus

Une fois le workshop terminÃ©, essayez ces dÃ©fis :

### DÃ©fi 1 : Ajouter l'Authentification Ã  Jupyter
Modifiez le Dockerfile pour activer l'authentification :

```dockerfile
# Remplacer la derniÃ¨re ligne par :
CMD ["start-notebook.sh", "--NotebookApp.token='votre-token'"]
```

### DÃ©fi 2 : Ajouter PostgreSQL
Ajoutez un service PostgreSQL au docker-compose.yml :

```yaml
postgres:
  image: postgres:15-alpine
  environment:
    POSTGRES_PASSWORD: password
    POSTGRES_DB: analytics
  ports:
    - "5432:5432"
  networks:
    - dataflow-insight-net
```

### DÃ©fi 3 : Optimiser l'Image Docker
Utilisez une image multi-stage pour rÃ©duire la taille :

```dockerfile
# Build stage
FROM jupyter/pyspark-notebook:spark-3.5.0 as builder
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Runtime stage
FROM jupyter/pyspark-notebook:spark-3.5.0
COPY --from=builder /opt/conda /opt/conda
```

### DÃ©fi 4 : Ajouter un Dashboard
Ajoutez un service Streamlit pour visualiser les donnÃ©es MongoDB

### DÃ©fi 5 : Automatiser le Chargement
CrÃ©ez un script Python qui charge automatiquement les donnÃ©es au dÃ©marrage

### DÃ©fi 6 : Monitoring
Ajoutez MongoDB Express pour une interface web de MongoDB :

```yaml
mongo-express:
  image: mongo-express
  ports:
    - "8081:8081"
  environment:
    ME_CONFIG_MONGODB_SERVER: mongodb
  networks:
    - dataflow-insight-net
```

---

## ğŸ“š Ressources SupplÃ©mentaires

- [Documentation Docker](https://docs.docker.com/)
- [Documentation Docker Compose](https://docs.docker.com/compose/)
- [Documentation Jupyter](https://jupyter-docker-stacks.readthedocs.io/)
- [Documentation PySpark](https://spark.apache.org/docs/latest/api/python/)
- [Documentation MongoDB](https://www.mongodb.com/docs/)
- [Documentation PyMongo](https://pymongo.readthedocs.io/)

---

## ğŸ’¡ Conseils et Bonnes Pratiques

### DÃ©veloppement
- ğŸ”„ Utilisez `--build` pour reconstruire aprÃ¨s modification du Dockerfile
- ğŸ“ Gardez `requirements.txt` Ã  jour
- ğŸ’¾ Sauvegardez rÃ©guliÃ¨rement vos notebooks
- ğŸ§¹ Nettoyez les volumes et images inutilisÃ©s rÃ©guliÃ¨rement

### SÃ©curitÃ©
- ğŸ”’ Ne dÃ©sactivez jamais l'authentification en production
- ğŸ”‘ Utilisez des variables d'environnement pour les secrets
- ğŸ‘¤ ExÃ©cutez toujours en tant qu'utilisateur non-root quand possible
- ğŸŒ Ne exposez pas les ports sensibles publiquement

### Performance
- âš¡ Utilisez `--no-cache-dir` avec pip pour rÃ©duire la taille des images
- ğŸ“¦ Ordonnez les instructions Dockerfile du moins au plus changeant
- ğŸ’¿ Utilisez des volumes nommÃ©s pour les donnÃ©es importantes
- ğŸ¯ Limitez les ressources si nÃ©cessaire (CPU, RAM)

---

Bon workshop ! ğŸš€ğŸ³ğŸ“Š
