# DataFlow Insight - Configuration Docker

Ce projet configure un environnement de data science avec Jupyter Notebook, PySpark et MongoDB.

---

## üìã Architecture du Projet

Le projet est compos√© de deux services principaux :
1. **MongoDB** - Base de donn√©es NoSQL pour stocker les donn√©es
2. **Jupyter Notebook** - Environnement de d√©veloppement avec PySpark pour l'analyse de donn√©es

---

## üìÑ Dockerfile

Le Dockerfile cr√©e une image personnalis√©e bas√©e sur Jupyter avec PySpark.

```dockerfile
# Image de base : Jupyter avec PySpark 3.5.0 pr√©install√©
FROM jupyter/pyspark-notebook:spark-3.5.0

# Passage en mode root pour installer des paquets syst√®me
USER root

# Installation des outils MongoDB et d√©pendances syst√®me
RUN apt-get update && apt-get install -y \
    wget \              # Outil de t√©l√©chargement
    curl \              # Outil de transfert de donn√©es
    && rm -rf /var/lib/apt/lists/*  # Nettoyage du cache pour r√©duire la taille de l'image

# Retour √† l'utilisateur jovyan (utilisateur par d√©faut de Jupyter)
USER $NB_UID

# D√©finition du r√©pertoire de travail
WORKDIR /home/jovyan/work

# Copie du fichier des d√©pendances Python
COPY requirements.txt .

# Installation des d√©pendances Python
RUN pip install --no-cache-dir -r requirements.txt

# Copie des fichiers du projet avec les bonnes permissions
COPY --chown=$NB_UID:$NB_GID . .

# Exposition du port Jupyter Notebook
EXPOSE 8888

# Exposition du port Spark UI (interface de monitoring Spark)
EXPOSE 4040

# Commande de d√©marrage : lance Jupyter sans authentification
CMD ["start-notebook.sh", "--NotebookApp.token=''", "--NotebookApp.password=''"]
```

### üîç Explication des instructions :

- **FROM** : Utilise l'image officielle Jupyter avec PySpark pr√©install√©
- **USER root** : Passe en mode administrateur pour installer des packages syst√®me
- **RUN apt-get** : Installe wget et curl pour t√©l√©charger des fichiers
- **USER $NB_UID** : Revient √† l'utilisateur non-privil√©gi√© pour la s√©curit√©
- **WORKDIR** : D√©finit `/home/jovyan/work` comme r√©pertoire de travail
- **COPY requirements.txt** : Copie le fichier des d√©pendances Python
- **RUN pip install** : Installe les packages Python list√©s dans requirements.txt
- **COPY --chown** : Copie tous les fichiers du projet avec les bonnes permissions
- **EXPOSE** : Documente les ports utilis√©s (8888 pour Jupyter, 4040 pour Spark UI)
- **CMD** : D√©marre Jupyter sans mot de passe (√† modifier en production !)

---

## üê≥ Docker Compose

Le fichier `docker-compose.yml` orchestre les services et d√©finit l'architecture multi-conteneurs.

```yaml
version: '3.8'

services:
  # Service MongoDB
  mongodb:
    image: mongo:7.0                          # Image MongoDB version 7.0
    container_name: dataflow-insight-mongo    # Nom du conteneur
    ports:
      - "27017:27017"                         # Port MongoDB (host:container)
    environment:
      MONGO_INITDB_DATABASE: dataflow_insight # Nom de la base de donn√©es initiale
    volumes:
      - mongodb_data:/data/db                 # Persistance des donn√©es MongoDB
    networks:
      - dataflow-insight-net                  # R√©seau partag√©

  # Service Jupyter avec PySpark
  jupyter:
    build: .                                  # Construction depuis le Dockerfile local
    container_name: dataflow-insight-jupyter  # Nom du conteneur
    ports:
      - "8888:8888"                           # Port Jupyter Notebook
      - "4041:4040"                           # Port Spark UI (redirig√© vers 4041 sur l'h√¥te)
    environment:
      - JUPYTER_ENABLE_LAB=yes                # Active JupyterLab (interface moderne)
      - GRANT_SUDO=yes                        # Autorise les commandes sudo dans le conteneur
    volumes:
      - ./data:/home/jovyan/work/data                     # Dossier data partag√©
      - ./load.ipynb:/home/jovyan/work/load.ipynb         # Notebook principal
      - ./notebooks:/home/jovyan/work/notebooks           # Dossier notebooks partag√©
    depends_on:
      - mongodb                               # D√©marre MongoDB avant Jupyter
    networks:
      - dataflow-insight-net                  # R√©seau partag√© avec MongoDB

# D√©claration des volumes persistants
volumes:
  mongodb_data:                               # Volume pour stocker les donn√©es MongoDB

# D√©claration des r√©seaux
networks:
  dataflow-insight-net:                       # R√©seau bridge pour la communication inter-conteneurs
    driver: bridge
```

### üîç Explication de la configuration :

#### **Service MongoDB**
- **image: mongo:7.0** : Utilise l'image officielle MongoDB version 7.0
- **ports: "27017:27017"** : Expose MongoDB sur le port par d√©faut
- **environment** : Cr√©e automatiquement une base de donn√©es nomm√©e `dataflow_insight`
- **volumes** : Persiste les donn√©es dans un volume Docker nomm√© `mongodb_data`
- **networks** : Connect√© au r√©seau `dataflow-insight-net` pour communiquer avec Jupyter

#### **Service Jupyter**
- **build: .** : Construit l'image √† partir du Dockerfile dans le r√©pertoire courant
- **ports** : 
  - `8888:8888` ‚Üí Acc√®s √† Jupyter via http://localhost:8888
  - `4041:4040` ‚Üí Acc√®s √† Spark UI via http://localhost:4041
- **environment** :
  - `JUPYTER_ENABLE_LAB=yes` : Active l'interface JupyterLab moderne
  - `GRANT_SUDO=yes` : Permet d'ex√©cuter des commandes root si n√©cessaire
- **volumes** : Montage bidirectionnel pour :
  - Partager les donn√©es entre l'h√¥te et le conteneur
  - √âditer les notebooks directement depuis l'h√¥te
  - Persister le travail m√™me si le conteneur est supprim√©
- **depends_on** : Assure que MongoDB d√©marre avant Jupyter
- **networks** : Permet √† Jupyter de se connecter √† MongoDB via le nom `mongodb`

#### **Volumes**
- **mongodb_data** : Volume g√©r√© par Docker pour persister les donn√©es de MongoDB

#### **Networks**
- **dataflow-insight-net** : R√©seau de type bridge permettant aux conteneurs de communiquer entre eux par leur nom

---

## üöÄ Utilisation

### D√©marrer les services
```bash
docker-compose up -d
```

### Acc√©der aux services
- **Jupyter Notebook** : http://localhost:8888
- **Spark UI** : http://localhost:4041 (quand Spark est actif)
- **MongoDB** : localhost:27017

### Connexion √† MongoDB depuis Jupyter
Dans vos notebooks, utilisez l'URL de connexion :
```python
mongo_url = "mongodb://mongodb:27017/dataflow_insight"
```

### Arr√™ter les services
```bash
docker-compose down
```

### Arr√™ter et supprimer les donn√©es
```bash
docker-compose down -v
```

---

## üìÅ Structure du Projet

```
.
‚îú‚îÄ‚îÄ Dockerfile              # Configuration de l'image Jupyter personnalis√©e
‚îú‚îÄ‚îÄ docker-compose.yml      # Orchestration des services
‚îú‚îÄ‚îÄ requirements.txt        # D√©pendances Python
‚îú‚îÄ‚îÄ load.ipynb              # Notebook principal
‚îú‚îÄ‚îÄ data/                   # Dossier des donn√©es (partag√©)
‚îî‚îÄ‚îÄ notebooks/              # Dossier des notebooks (partag√©)
```

---

## ‚ö†Ô∏è Notes de S√©curit√©

- **Authentification d√©sactiv√©e** : Le Jupyter d√©marre sans mot de passe (`--NotebookApp.token=''`)
  - ‚ö†Ô∏è **√Ä ne pas utiliser en production !**
  - Pour activer l'authentification, supprimez cette option du CMD dans le Dockerfile
  
- **Sudo activ√©** : `GRANT_SUDO=yes` permet des commandes root dans le conteneur
  - Utile pour le d√©veloppement, mais risqu√© en production

---

## üîß Personnalisation

### Ajouter des packages Python
√âditez le fichier `requirements.txt` et reconstruisez l'image :
```bash
docker-compose build
docker-compose up -d
```

### Modifier les ports
Changez les ports dans `docker-compose.yml`, par exemple :
```yaml
ports:
  - "9999:8888"  # Jupyter accessible sur le port 9999
```

### Ajouter des variables d'environnement
Ajoutez-les dans la section `environment` du service concern√© :
```yaml
environment:
  - MA_VARIABLE=valeur
```